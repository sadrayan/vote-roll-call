{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "from urllib.request import urlopen\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display \n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    \n",
    "plt.style.use('seaborn-paper')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'http://clerk.house.gov/evs/{session}/roll{roll}.xml'\n",
    "\n",
    "link_list = []\n",
    "\n",
    "congress_session  = {'2018' : 129,\n",
    "                     '2017' : 710,\n",
    "                     '2016' : 622,\n",
    "                     '2015' : 705, \n",
    "                     '2014' : 564,\n",
    "                     '2013' : 641,\n",
    "                     '2012' : 659,\n",
    "                     '2011' : 949,\n",
    "                     '2010' : 664,\n",
    "                     '2009' : 991,\n",
    "                     '2008' : 690,\n",
    "                     '2007' : 1186,\n",
    "                     '2006' : 543,\n",
    "                     '2005' : 671,\n",
    "                     '2004' : 544,\n",
    "                     '2003' : 677,\n",
    "                     '2002' : 484,\n",
    "                     '2001' : 512,\n",
    "                     '2000' : 603\n",
    "                    }\n",
    "\n",
    "for session, roll  in congress_session.items():\n",
    "#     print(session, roll)\n",
    "    for i in range (1, roll + 1):\n",
    "        temp = link.replace('{session}', session)\n",
    "        temp = temp.replace('{roll}', '{:03}'.format(i))\n",
    "        link_list.append(temp)\n",
    "\n",
    "print('link_list', len(link_list))\n",
    "print(link_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         <majority>D</majority>\n",
    "#         <congress>103</congress>\n",
    "#         <session>1st</session>\n",
    "#         <chamber>U.S. House of Representatives</chamber>\n",
    "#         <rollcall-num>615</rollcall-num>\n",
    "#         <legis-num>H R 3167</legis-num>\n",
    "#         <vote-question>On Agreeing to the Conference Report</vote-question>\n",
    "#         <vote-type>RECORDED VOTE</vote-type>\n",
    "#         <vote-result>Passed</vote-result>\n",
    "#         <action-date>22-Nov-1993</action-date>\n",
    "#         <action-time time-etz=\"23:59\">11:59 PM</action-time>\n",
    "#         <vote-desc>UNEMPLOYMENT COMPENSATION...</vote-desc>\n",
    "\n",
    "#         <recorded-vote>\n",
    "#             <legislator party=\"D\" state=\"HI\" role=\"legislator\">Abercrombie</legislator>\n",
    "#             <vote>Aye</vote>\n",
    "#         </recorded-vote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml2df(xml_data):\n",
    "#     print(xml_data)\n",
    "    root = ET.XML(xml_data) # element tree\n",
    "#     print(root)\n",
    "    vote_metadata = root.find('vote-metadata')\n",
    "    vote_data = root.find('vote-data').iter('recorded-vote')\n",
    "    records = []\n",
    "    \n",
    "    for vote in vote_data:\n",
    "        record = {} #Place holder for our record\n",
    "        record['majority'] = vote_metadata.find('majority').text\n",
    "        record['congress'] = vote_metadata.find('congress').text\n",
    "        record['session'] = vote_metadata.find('session').text\n",
    "\n",
    "        try:\n",
    "            record['chamber'] = vote_metadata.find('chamber').text\n",
    "        except Exception:\n",
    "            record['chamber'] = None\n",
    "\n",
    "        record['rollcall_num'] = vote_metadata.find('rollcall-num').text\n",
    "        try:\n",
    "            record['legis_num'] = vote_metadata.find('legis-num').text\n",
    "        except Exception:\n",
    "            record['legis_num'] = None\n",
    "\n",
    "        record['vote_question'] = vote_metadata.find('vote-question').text\n",
    "        record['vote_type'] = vote_metadata.find('vote-type').text\n",
    "        record['vote_result'] = vote_metadata.find('vote-result').text\n",
    "        record['action_date'] = vote_metadata.find('action-date').text\n",
    "        record['action_time'] = vote_metadata.find('action-time').text\n",
    "        record['vote_desc'] = vote_metadata.find('vote-desc').text\n",
    "    \n",
    "        record['party'] = vote.find('legislator').attrib['party']\n",
    "        record['state'] = vote.find('legislator').attrib['state']\n",
    "        record['role'] = vote.find('legislator').attrib['role']\n",
    "        record['name'] = vote.find('legislator').text\n",
    "        \n",
    "        if any(vote.find('vote').text in s for s in ['Yea', 'Aye']):\n",
    "            record['vote'] = 'Yea'\n",
    "        elif any(vote.find('vote').text in s for s in ['No', 'Nay']):\n",
    "            record['vote'] = 'Nay'\n",
    "        else:\n",
    "            continue\n",
    "        records.append(record)\n",
    "        \n",
    "    return pd.DataFrame(records)\n",
    "    \n",
    "    \n",
    "# xml = urlopen(link_list[2]).read()\n",
    "# df = xml2df(xml)\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def processLink(link):\n",
    "#     print('processing', link)\n",
    "    urlContent = urlopen(link)\n",
    "    xml = urlContent.read()\n",
    "    return xml2df(xml)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print('num_cores', num_cores)\n",
    "\n",
    "# processLink(link_list[2])\n",
    "    \n",
    "results = Parallel(n_jobs=num_cores)(delayed(processLink)(i) for i in tqdm(link_list))\n",
    "\n",
    "df_votes = pd.concat(results)\n",
    "df_votes.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# df_hansard['date'] =  pd.to_datetime(df_hansard['date'])\n",
    "\n",
    "df_votes.to_csv('../data/votes_all.csv')\n",
    "print(len(df_votes))\n",
    "\n",
    "df_votes.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_votes = df_votes[df_votes['vote'].isin(['Yea', 'Aye', 'No', 'Nay'])]\n",
    "df_votes['vote'].value_counts().plot(kind='bar', alpha=.5, figsize=(12, 6), fontsize=14)\n",
    "df_votes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_votes = pd.read_csv('../data/votes_all.csv')\n",
    "df_filtered = df_votes.drop_duplicates('legis_num', keep='first')\n",
    "df_filtered.reset_index(inplace=True)\n",
    "df_filtered.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "link = 'https://www.congress.gov/bill/{congress}th-congress/house-bill/{billNum}/text?format=txt&r=1'\n",
    "\n",
    "def creat_list(row):\n",
    "#     print(row)\n",
    "    link_temp = link.replace('{congress}', str(row['congress']))\n",
    "    return link_temp.replace('{billNum}', ''.join(re.findall('\\d+', row['legis_num'])))\n",
    "\n",
    "\n",
    "df_filtered['link'] = df_filtered.apply(creat_list, axis=1)\n",
    "df_filtered.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "STOPLIST = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS))\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\", ' ', '', '``', '--', '''''',]\n",
    "\n",
    "def tokenizeText(text):\n",
    "#     print('hereeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee', text)\n",
    "    tokens = []\n",
    "    for tok in nlp(text):\n",
    "        tokens.append(tok.text.strip())\n",
    "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "    tokens = [tok for tok in tokens if not tok.isdigit()]\n",
    "    return u' '.join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from multiprocessing import Pool\n",
    "\n",
    "num_partitions = 10 #number of partitions to split dataframe\n",
    "num_cores = 7 #number of cores on your machine\n",
    "\n",
    "\n",
    "def processBillLink(link):\n",
    "    billText = ''\n",
    "    try:\n",
    "        req = urllib.request.Request(link, headers={'User-Agent' : \"Magic Browser\"}) \n",
    "        htmlContent = urllib.request.urlopen(req).read()\n",
    "        \n",
    "        soup = BeautifulSoup(htmlContent, 'lxml')\n",
    "        billText = soup.find(\"pre\", {\"id\": \"billTextContainer\"}).text\n",
    "        billText = tokenizeText(billText[:999999].lower()) # trunkate for Spacy\n",
    "    except Exception:\n",
    "        print('didnt find', link)\n",
    "        pass\n",
    "\n",
    "    return billText\n",
    "\n",
    "# processBillLink(df_filtered['link'][1])\n",
    "\n",
    "link_list = df_filtered['link'].tolist()\n",
    "print(link_list[1])\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print('num_cores', num_cores)\n",
    "results = Parallel(n_jobs=num_cores)(delayed(processBillLink)(i) for i in tqdm(link_list[:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[1])\n",
    "df_filtered['billText'] = results\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    " \n",
    "data = \"All work and no play makes jack a dull boy, all work and no play\"\n",
    "# print(word_tokenize(df_filtered['billText'][1]))\n",
    "print(parser(df_filtered['billText'][1]))\n",
    "\n",
    "\n",
    "# print(tokenizeText(u' '.join(df_filtered['billText'][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results[1])\n",
    "\n",
    "df_filtered['billText'] = df_filtered['billText'].apply(tokenizeText) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# records = []\n",
    "link_list = []\n",
    "# congress = '115'\n",
    "print('bills',  len(df_votes['legis_num'].unique()))\n",
    "\n",
    "\n",
    "\n",
    "for row in tqdm(df_votes['legis_num'].unique()):\n",
    "\n",
    "        \n",
    "df_bill = pd.DataFrame(records)\n",
    "print('found ', len(df_bill), ' out of ', len(df_votes['legis_num'].unique()))\n",
    "df_bill.to_csv('../data/bill_all.csv')\n",
    "df_bill.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bill.to_csv('../data/bill_all.csv')\n",
    "df_bill.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
