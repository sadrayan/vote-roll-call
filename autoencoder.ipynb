{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Add, Multiply\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer, FeatureHasher\n",
    "encoder = FeatureHasher(n_features=10, input_type=\"string\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "feature_all = {}\n",
    "y_all = {}\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "n_components = 20\n",
    "    \n",
    "for name, group in tqdm(df_final.groupby('congress')):\n",
    "    print('Processing congress', name)\n",
    "    print('congress shape', group.shape)  \n",
    "    \n",
    "#     print(encoder.fit_transform(group[['sponsor_id', 'sponsor_party', 'sponsor_state']]).shape)\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=10000,\n",
    "                                   stop_words='english')\n",
    "\n",
    "    \n",
    "    group['sponsor_id'] = encoder.fit_transform(group['sponsor_id'])\n",
    "    group['sponsor_party'] = encoder.fit_transform(group['sponsor_party'])\n",
    "    group['sponsor_state'] = encoder.fit_transform(group['sponsor_state'])\n",
    "#     tf_idf_desc = tfidf_vectorizer.fit_transform(group['vote_desc'].values.astype('U'))\n",
    "#     print('tf_idf shape', tf_idf_desc.shape)\n",
    "#     nmf = NMF(n_components=n_components, \n",
    "#               random_state=1, beta_loss='kullback-leibler', \n",
    "#               solver='mu', max_iter=1000, alpha=.1, l1_ratio=.5).fit_transform(tf_idf_desc)\n",
    "#     print('nmf shape', nmf.shape)\n",
    "\n",
    "    X = group[['sponsor_id', 'sponsor_party', 'sponsor_state']]\n",
    "#     print(X)\n",
    "#     X = np.hstack((group['sponsor_id'].values.reshape(-1,1), \n",
    "#                    group['sponsor_party'].values.reshape(-1,1), \n",
    "#                    group['sponsor_state'].values.reshape(-1,1)))\n",
    "    \n",
    "\n",
    "#     X = np.hstack((encoder.fit_transform(group['sponsor_id']).reshape(-1,1), \n",
    "#                    encoder.fit_transform(group['sponsor_party']).reshape(-1,1), \n",
    "#                    encoder.fit_transform(group['sponsor_state']).reshape(-1,1)))\n",
    "#     X = pd.DataFrame(X)\n",
    "#     print(X.describe())\n",
    "#     print(list(encoder.classes_))\n",
    "\n",
    "    y = group['vote']\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y)\n",
    "#     print(le.classes_)\n",
    "    y = le.transform(y)\n",
    "    print(X[:1])\n",
    "    print(y[:1])\n",
    "\n",
    "    print('X shape', X.shape)\n",
    "    print('y shape', y.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, random_state=42)\n",
    "\n",
    "    print('X_train', X_train.shape, 'y_train', y_train.shape)\n",
    "    print('X_test', X_test.shape, 'y_test', y_test.shape)\n",
    "\n",
    "    \n",
    "    print((group['vote'].value_counts()))\n",
    "#     group['vote'].value_counts().plot(kind='bar', alpha=.5)\n",
    "    group['sponsor_state'].value_counts()[:10].plot(kind='bar', alpha=.5)\n",
    "             \n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 435)\n",
      "(167,)\n",
      "(167, 17563)\n",
      "(167, 17563)\n",
      "(167, 300)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vote_matrix_all = np.load('data/vote_matrix_all.npy' )\n",
    "X_seq_all = np.load('data/X_seq_all.npy')\n",
    "word_index_all = np.load('data/X_word_index_all.npy')\n",
    "X_train_tf_all = np.load('data/X_train_tf_all.npy')\n",
    "X_train_counts_all = np.load('data/X_train_counts_all.npy')\n",
    "X_emb_all = np.load('data/X_emb_all.npy')\n",
    "legistlator_all = np.load('data/legistlator_all.npy')\n",
    "\n",
    "print(vote_matrix_all.item()[106].shape)\n",
    "print(X_seq_all.item()[106].shape)\n",
    "# print(word_index_all[106].shape)\n",
    "print(X_train_tf_all.item()[106].shape)\n",
    "print(X_train_counts_all.item()[106].shape)\n",
    "print(X_emb_all.item()[106].shape)\n",
    "# print(legistlator_all.item()[106])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variational\n",
    "\n",
    "def nll(y_true, y_pred):\n",
    "    \"\"\" Negative log likelihood (Bernoulli). \"\"\"\n",
    "\n",
    "    # keras.losses.binary_crossentropy gives the mean\n",
    "    # over the last axis. we require the sum\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "\n",
    "class KLDivergenceLayer(Layer):\n",
    "\n",
    "    \"\"\" Identity transform layer that adds KL divergence\n",
    "    to the final model loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        mu, log_var = inputs\n",
    "\n",
    "        kl_batch = - .5 * K.sum(1 + log_var -\n",
    "                                K.square(mu) -\n",
    "                                K.exp(log_var), axis=-1)\n",
    "\n",
    "        self.add_loss(K.mean(kl_batch), inputs=inputs)\n",
    "\n",
    "        return inputs\n",
    "\n",
    "\n",
    "def get_VAE(original_dim):\n",
    "    decoder = Sequential([\n",
    "        Dense(intermediate_dim, input_dim=latent_dim, activation='relu'),\n",
    "        Dense(original_dim, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    x = Input(shape=(original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='relu')(x)\n",
    "\n",
    "    z_mu = Dense(latent_dim)(h)\n",
    "    z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "    z_mu, z_log_var = KLDivergenceLayer()([z_mu, z_log_var])\n",
    "    z_sigma = Lambda(lambda t: K.exp(.5*t))(z_log_var)\n",
    "\n",
    "    eps = Input(tensor=K.random_normal(stddev=epsilon_std,\n",
    "                                       shape=(K.shape(x)[0], latent_dim)))\n",
    "    z_eps = Multiply()([z_sigma, eps])\n",
    "    z = Add()([z_mu, z_eps])\n",
    "\n",
    "    x_pred = decoder(z)\n",
    "\n",
    "    vae = Model(inputs=[x, eps], outputs=x_pred)\n",
    "    \n",
    "    loss = nll\n",
    "    loss = 'mean_squared_error'\n",
    "    vae.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "    encoder = Model(x, z_mu)\n",
    "    return vae, encoder, decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import glorot_uniform  # Or your initializer of choice\n",
    "\n",
    "def reinitialize(model):\n",
    "    initial_weights = model.get_weights()\n",
    "    new_weights = [glorot_uniform()(w.shape).eval() for w in initial_weights]\n",
    "    model.set_weights(new_weights)\n",
    "    return model\n",
    "      \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_emb (167, 300)\n",
      "vote_matrix (167, 435)\n",
      "X_meta (435, 167, 300)\n",
      "X_train (435, 167, 300)\n",
      "X_train new shape (435, 167, 300)\n",
      "X_meta new shape (435, 167, 300)\n",
      "(167, 300)\n",
      "[[ 0.4825354  -0.87425696  0.32159408 ... -0.26271629 -0.64067532\n",
      "  -0.27780402]\n",
      " [ 0.46867788 -0.58312602  0.48291334 ...  0.00436518 -0.41854216\n",
      "   0.0656492 ]\n",
      " [-0.01082105  0.19470767  0.06788067 ... -0.03374893  0.05979728\n",
      "   0.08913655]\n",
      " ...\n",
      " [-0.26898635  0.36104397  1.         ...  1.          1.\n",
      "   0.2320706 ]\n",
      " [ 0.01469368  0.06445051  0.06595016 ... -0.01713964  0.09726893\n",
      "  -0.03515295]\n",
      " [ 0.04494724  0.03371028 -0.04445521 ...  0.01391445 -0.08335289\n",
      "   0.04289823]]\n"
     ]
    }
   ],
   "source": [
    "X_emb = X_emb_all.item()[106]\n",
    "vote_matrix = vote_matrix_all.item()[106]\n",
    "print('X_emb', X_emb.shape)\n",
    "print('vote_matrix', vote_matrix.shape)\n",
    "\n",
    "# numpyMatrix = df.as_matrix().astype(float)\n",
    "# scaled_data = preprocessing.scale(numpyMatrix)\n",
    "\n",
    "from sklearn.preprocessing import scale, MinMaxScaler, StandardScaler\n",
    "# X_emb = StandardScaler().fit_transform(X_emb.astype(float))\n",
    "X_emb = scale(X_emb.astype(float))\n",
    "\n",
    "X = []\n",
    "X_meta = []\n",
    "y = []\n",
    "i = 0\n",
    "\n",
    "#     mean = 0.0   # some constant\n",
    "#     std = 1.0    # some constant (standard deviation)\n",
    "#     meta = meta + np.random.normal(mean, std, meta.shape)\n",
    "mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "noise_factor = 0.5\n",
    "\n",
    "X_train = []\n",
    "######\n",
    "# Create Meta for each legistlator\n",
    "for idx, legistlator in enumerate(vote_matrix.T):\n",
    "#     print('np.vstack(legistlator)', np.vstack(legistlator).shape)\n",
    "#     print('legistlator.shape', legistlator.shape)\n",
    "#     legistlator = legistlator + np.random.normal(mu, sigma, legistlator.shape)\n",
    "\n",
    "    meta = np.multiply(X_emb, np.vstack(legistlator)) # Eelementwise multiplication, introducing noise\n",
    "\n",
    "\n",
    "    meta = meta + noise_factor * np.random.normal(mu, sigma, meta.shape)\n",
    "\n",
    "#     print('meta.shape', meta.shape)\n",
    "    \n",
    "    X_meta.append(meta)\n",
    "    X_train.append(X_emb)\n",
    "\n",
    "#     break\n",
    "######\n",
    "X_meta = np.array(X_meta)\n",
    "X_train = np.array(X_train)\n",
    "print('X_meta', X_meta.shape)\n",
    "print('X_train', X_train.shape)\n",
    "\n",
    "\n",
    "# Reshape to flatten the dimentions\n",
    "# X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "# X_meta = X_meta.reshape(X_meta.shape[0], -1)\n",
    "# X_train = X_train.reshape(-1, X_train.shape[1], X_train.shape[2], 1)\n",
    "# X_meta = X_meta.reshape(-1, X_meta.shape[1], X_meta.shape[2], 1)\n",
    "\n",
    "X_train =  np.clip(X_train, -1., 1.)\n",
    "X_meta = np.clip(X_meta, -1., 1.)\n",
    "print('X_train new shape', X_train.shape)\n",
    "print('X_meta new shape', X_meta.shape)\n",
    "\n",
    "print(X_train[0].shape)\n",
    "print(X_meta[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_autoencoder(X_train):\n",
    "    input_img = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    encoded = Dense(128, activation='relu', kernel_initializer='glorot_uniform')(input_img)\n",
    "    encoded = Dense(64, activation='relu')(encoded)\n",
    "    encoded = Dense(32, activation='relu',  name='encoded')(encoded)\n",
    "\n",
    "    decoded = Dense(64, activation='relu')(encoded)\n",
    "    decoded = Dense(128, activation='relu')(decoded)\n",
    "    decoded = Dense(X_train.shape[2], activation='sigmoid')(decoded)\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "#     loss = 'mean_squared_error'\n",
    "    loss='binary_crossentropy'\n",
    "    autoencoder.compile(optimizer='adam', loss=loss)\n",
    "    return autoencoder\n",
    "\n",
    "def denoiser_autoencoder(X_train):\n",
    "#     input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "    input_img = Input(shape = (X_train.shape[1], X_train.shape[2], 1 ))\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='glorot_uniform')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    # at this point the representation is (7, 7, 32)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return autoencoder\n",
    "\n",
    "    \n",
    "from keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D\n",
    "\n",
    "\n",
    "def conv_autoencoder(X_train):\n",
    "    \n",
    "    input_img = Input(shape = (1, X_train.shape[1], X_train.shape[2] ))\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', name='encoded')(pool2) #7 x 7 x 128 (small and thick)\n",
    "\n",
    "    #decoder\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 128\n",
    "    up1 = UpSampling2D((2,2))(conv4) # 14 x 14 x 128\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 64\n",
    "    up2 = UpSampling2D((2,2))(conv5) # 28 x 28 x 64\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='decoded')(up2) # 28 x 28 x 1\n",
    "    \n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(loss='mean_squared_error', optimizer = 'RMSprop')\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 167, 300)          0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 167, 128)          38528     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 167, 64)           8256      \n",
      "_________________________________________________________________\n",
      "encoded (Dense)              (None, 167, 32)           2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 167, 64)           2112      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 167, 128)          8320      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 167, 300)          38700     \n",
      "=================================================================\n",
      "Total params: 97,996\n",
      "Trainable params: 97,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "ShuffleSplit(n_splits=3, random_state=0, test_size=0.25, train_size=None)\n",
      "(326, 167, 300) (109, 167, 300)\n",
      "(326, 167, 300) (109, 167, 300)\n",
      "Epoch 1/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.6904\n",
      "Epoch 2/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.6730\n",
      "Epoch 3/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.6433\n",
      "Epoch 4/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5953\n",
      "Epoch 5/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5263\n",
      "Epoch 6/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4357\n",
      "Epoch 7/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.3285\n",
      "Epoch 8/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.2167\n",
      "Epoch 9/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.1155\n",
      "Epoch 10/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.0342\n",
      "Epoch 11/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: -0.0305\n",
      "Epoch 12/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: -0.0805\n",
      "Epoch 13/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: -0.1155\n",
      "Epoch 14/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: -0.1512\n",
      "Epoch 15/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: -0.2112\n",
      "Epoch 16/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: -0.2942\n",
      "Epoch 17/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: -0.3862\n",
      "Epoch 18/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: -0.4815\n",
      "Epoch 19/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: -0.5788\n",
      "Epoch 20/20\n",
      "326/326 [==============================] - 1s 3ms/step - loss: -0.6715\n",
      "{'loss': [0.6904189582982677, 0.6729565372496294, 0.6432871749064674, 0.5953153839871927, 0.5262904386578894, 0.43572628845466427, 0.32853672712858467, 0.21670546359811094, 0.11551135481318082, 0.034183736062077294, -0.030453465581854428, -0.08052194337903357, -0.11550462319075695, -0.15118216599789133, -0.21120737365052744, -0.29418273937482775, -0.38622984216988454, -0.4814717820816976, -0.5788400308486142, -0.6714607528382284]}\n",
      "dense_6/kernel:0 (300, 128)\n",
      "dense_6/bias:0 (128,)\n",
      "dense_7/kernel:0 (128, 64)\n",
      "dense_7/bias:0 (64,)\n",
      "encoded_1/kernel:0 (64, 32)\n",
      "encoded_1/bias:0 (32,)\n",
      "dense_8/kernel:0 (32, 64)\n",
      "dense_8/bias:0 (64,)\n",
      "dense_9/kernel:0 (64, 128)\n",
      "dense_9/bias:0 (128,)\n",
      "dense_10/kernel:0 (128, 300)\n",
      "dense_10/bias:0 (300,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################\n",
    "# original_dim = \n",
    "intermediate_dim = 256\n",
    "latent_dim = 128\n",
    "batch_size = 256\n",
    "epochs = 20\n",
    "epsilon_std = 1.0\n",
    "###################\n",
    "\n",
    "# autoencoder, encoder, decoder = get_VAE(original_dim)\n",
    "autoencoder = deep_autoencoder(X_train)\n",
    "# autoencoder = denoiser_autoencoder(X_train)\n",
    "# autoencoder = conv_autoencoder(X_train)\n",
    "print(autoencoder.summary())\n",
    "\n",
    "rs = ShuffleSplit(n_splits=3, test_size=.25, random_state=0)\n",
    "rs.get_n_splits(X_train)\n",
    "\n",
    "print(rs)\n",
    "\n",
    "def plot_history(history):\n",
    "    print(history.history)\n",
    "    df = pd.DataFrame(history.history)\n",
    "#     print(df.tail())\n",
    "    df.plot(xticks=range(epochs))\n",
    "#     print(history.history.keys())\n",
    "\n",
    "    \n",
    "for train_index, test_index in rs.split(X_train):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_emb_train, X_emb_test = X_train[train_index], X_train[test_index]\n",
    "    X_meta_train, X_meta_test = X_meta[train_index], X_meta[test_index]\n",
    "    \n",
    "    print(X_emb_train.shape, X_emb_test.shape)\n",
    "    print(X_meta_train.shape, X_meta_test.shape)\n",
    "#     break\n",
    "    \n",
    "    history = autoencoder.fit(X_emb_train,\n",
    "        X_meta_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    plot_history(history)\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    names = [weight.name for layer in autoencoder.layers for weight in layer.weights]\n",
    "    weights = autoencoder.get_weights()\n",
    "\n",
    "    for name, weight in zip(names, weights):\n",
    "        print(name, weight.shape)\n",
    "        \n",
    "#     encoded_weight = \n",
    "#     print(model_weights['encoded'].shape, model_weights['encoded'])\n",
    "\n",
    "    ###\n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into a training and testing set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
