{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from IPython.display import SVG\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Input\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim import utils\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "# plt.xkcd()\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1',\n",
      "       'index', 'Unnamed: 0.1.1.1.1', 'action_date', 'action_time', 'chamber',\n",
      "       'congress', 'legis_num', 'majority', 'name', 'party', 'role',\n",
      "       'rollcall_num', 'session', 'state', 'vote', 'vote_desc',\n",
      "       'vote_question', 'vote_result', 'vote_type', 'link', 'billText',\n",
      "       'sponsor', 'sponsor_id', 'sponsor_party', 'sponsor_state',\n",
      "       'sponsor_uri'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>action_date</th>\n",
       "      <th>action_time</th>\n",
       "      <th>chamber</th>\n",
       "      <th>congress</th>\n",
       "      <th>...</th>\n",
       "      <th>vote_question</th>\n",
       "      <th>vote_result</th>\n",
       "      <th>vote_type</th>\n",
       "      <th>link</th>\n",
       "      <th>billText</th>\n",
       "      <th>sponsor</th>\n",
       "      <th>sponsor_id</th>\n",
       "      <th>sponsor_party</th>\n",
       "      <th>sponsor_state</th>\n",
       "      <th>sponsor_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>4057</td>\n",
       "      <td>4057</td>\n",
       "      <td>4057</td>\n",
       "      <td>4057</td>\n",
       "      <td>5158792</td>\n",
       "      <td>5158792</td>\n",
       "      <td>13-Dec-2011</td>\n",
       "      <td>6:59 PM</td>\n",
       "      <td>U.S. House of Representatives</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>On Motion to Suspend the Rules and Pass</td>\n",
       "      <td>Passed</td>\n",
       "      <td>2/3 RECORDED VOTE</td>\n",
       "      <td>https://www.congress.gov/bill/112th-congress/h...</td>\n",
       "      <td>112th congress public law u.s government print...</td>\n",
       "      <td>John W. Olver</td>\n",
       "      <td>O000085</td>\n",
       "      <td>D</td>\n",
       "      <td>MA</td>\n",
       "      <td>https://api.propublica.org/congress/v1/members...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4058</th>\n",
       "      <td>4058</td>\n",
       "      <td>4058</td>\n",
       "      <td>4058</td>\n",
       "      <td>4058</td>\n",
       "      <td>5160455</td>\n",
       "      <td>5160455</td>\n",
       "      <td>14-Dec-2011</td>\n",
       "      <td>6:17 PM</td>\n",
       "      <td>U.S. House of Representatives</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>On Motion to Suspend the Rules and Pass, as Am...</td>\n",
       "      <td>Passed</td>\n",
       "      <td>2/3 YEA-AND-NAY</td>\n",
       "      <td>https://www.congress.gov/bill/112th-congress/h...</td>\n",
       "      <td>congressional bills 112th congress u.s governm...</td>\n",
       "      <td>Ileana Ros-Lehtinen</td>\n",
       "      <td>R000435</td>\n",
       "      <td>R</td>\n",
       "      <td>FL</td>\n",
       "      <td>https://api.propublica.org/congress/v1/members...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>4059</td>\n",
       "      <td>4059</td>\n",
       "      <td>4059</td>\n",
       "      <td>4059</td>\n",
       "      <td>5161291</td>\n",
       "      <td>5161291</td>\n",
       "      <td>14-Dec-2011</td>\n",
       "      <td>6:31 PM</td>\n",
       "      <td>U.S. House of Representatives</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>On Motion to Suspend the Rules and Pass, as Am...</td>\n",
       "      <td>Passed</td>\n",
       "      <td>2/3 YEA-AND-NAY</td>\n",
       "      <td>https://www.congress.gov/bill/112th-congress/h...</td>\n",
       "      <td>112th congress public law u.s government print...</td>\n",
       "      <td>Stephen Fincher</td>\n",
       "      <td>F000458</td>\n",
       "      <td>R</td>\n",
       "      <td>TN</td>\n",
       "      <td>https://api.propublica.org/congress/v1/members...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>4060</td>\n",
       "      <td>4060</td>\n",
       "      <td>4060</td>\n",
       "      <td>4060</td>\n",
       "      <td>5165452</td>\n",
       "      <td>5165452</td>\n",
       "      <td>16-Dec-2011</td>\n",
       "      <td>11:54 AM</td>\n",
       "      <td>U.S. House of Representatives</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>On Motion to Suspend the Rules and Pass, as Am...</td>\n",
       "      <td>Passed</td>\n",
       "      <td>2/3 RECORDED VOTE</td>\n",
       "      <td>https://www.congress.gov/bill/112th-congress/h...</td>\n",
       "      <td>congressional bills 112th congress u.s governm...</td>\n",
       "      <td>Mark Udall</td>\n",
       "      <td>U000038</td>\n",
       "      <td>D</td>\n",
       "      <td>CO</td>\n",
       "      <td>https://api.propublica.org/congress/v1/members...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061</th>\n",
       "      <td>4061</td>\n",
       "      <td>4061</td>\n",
       "      <td>4061</td>\n",
       "      <td>4061</td>\n",
       "      <td>5166702</td>\n",
       "      <td>5166702</td>\n",
       "      <td>16-Dec-2011</td>\n",
       "      <td>2:04 PM</td>\n",
       "      <td>U.S. House of Representatives</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>On Passage</td>\n",
       "      <td>Passed</td>\n",
       "      <td>YEA-AND-NAY</td>\n",
       "      <td>https://www.congress.gov/bill/112th-congress/h...</td>\n",
       "      <td>112th congress public law u.s government print...</td>\n",
       "      <td>Harold Rogers</td>\n",
       "      <td>R000395</td>\n",
       "      <td>R</td>\n",
       "      <td>KY</td>\n",
       "      <td>https://api.propublica.org/congress/v1/members...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1    index  \\\n",
       "4057        4057          4057            4057              4057  5158792   \n",
       "4058        4058          4058            4058              4058  5160455   \n",
       "4059        4059          4059            4059              4059  5161291   \n",
       "4060        4060          4060            4060              4060  5165452   \n",
       "4061        4061          4061            4061              4061  5166702   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1  action_date action_time  \\\n",
       "4057             5158792  13-Dec-2011     6:59 PM   \n",
       "4058             5160455  14-Dec-2011     6:17 PM   \n",
       "4059             5161291  14-Dec-2011     6:31 PM   \n",
       "4060             5165452  16-Dec-2011    11:54 AM   \n",
       "4061             5166702  16-Dec-2011     2:04 PM   \n",
       "\n",
       "                            chamber  congress  \\\n",
       "4057  U.S. House of Representatives       112   \n",
       "4058  U.S. House of Representatives       112   \n",
       "4059  U.S. House of Representatives       112   \n",
       "4060  U.S. House of Representatives       112   \n",
       "4061  U.S. House of Representatives       112   \n",
       "\n",
       "                            ...                          \\\n",
       "4057                        ...                           \n",
       "4058                        ...                           \n",
       "4059                        ...                           \n",
       "4060                        ...                           \n",
       "4061                        ...                           \n",
       "\n",
       "                                          vote_question vote_result  \\\n",
       "4057            On Motion to Suspend the Rules and Pass      Passed   \n",
       "4058  On Motion to Suspend the Rules and Pass, as Am...      Passed   \n",
       "4059  On Motion to Suspend the Rules and Pass, as Am...      Passed   \n",
       "4060  On Motion to Suspend the Rules and Pass, as Am...      Passed   \n",
       "4061                                         On Passage      Passed   \n",
       "\n",
       "              vote_type                                               link  \\\n",
       "4057  2/3 RECORDED VOTE  https://www.congress.gov/bill/112th-congress/h...   \n",
       "4058    2/3 YEA-AND-NAY  https://www.congress.gov/bill/112th-congress/h...   \n",
       "4059    2/3 YEA-AND-NAY  https://www.congress.gov/bill/112th-congress/h...   \n",
       "4060  2/3 RECORDED VOTE  https://www.congress.gov/bill/112th-congress/h...   \n",
       "4061        YEA-AND-NAY  https://www.congress.gov/bill/112th-congress/h...   \n",
       "\n",
       "                                               billText              sponsor  \\\n",
       "4057  112th congress public law u.s government print...        John W. Olver   \n",
       "4058  congressional bills 112th congress u.s governm...  Ileana Ros-Lehtinen   \n",
       "4059  112th congress public law u.s government print...      Stephen Fincher   \n",
       "4060  congressional bills 112th congress u.s governm...           Mark Udall   \n",
       "4061  112th congress public law u.s government print...        Harold Rogers   \n",
       "\n",
       "     sponsor_id sponsor_party sponsor_state  \\\n",
       "4057    O000085             D            MA   \n",
       "4058    R000435             R            FL   \n",
       "4059    F000458             R            TN   \n",
       "4060    U000038             D            CO   \n",
       "4061    R000395             R            KY   \n",
       "\n",
       "                                            sponsor_uri  \n",
       "4057  https://api.propublica.org/congress/v1/members...  \n",
       "4058  https://api.propublica.org/congress/v1/members...  \n",
       "4059  https://api.propublica.org/congress/v1/members...  \n",
       "4060  https://api.propublica.org/congress/v1/members...  \n",
       "4061  https://api.propublica.org/congress/v1/members...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bills = pd.read_csv('../data/bill_all.csv')\n",
    "print(df_bills.columns)\n",
    "df_bills.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yea' 'Nay']\n",
      "Index(['Unnamed: 0', 'level_0', 'index', 'Unnamed: 0.1', 'action_date',\n",
      "       'action_time', 'chamber', 'congress', 'legis_num', 'majority', 'name',\n",
      "       'party', 'role', 'rollcall_num', 'session', 'state', 'vote',\n",
      "       'vote_desc', 'vote_question', 'vote_result', 'vote_type', 'sponsor',\n",
      "       'sponsor_id', 'sponsor_party', 'sponsor_state', 'sponsor_uri'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>action_date</th>\n",
       "      <th>action_time</th>\n",
       "      <th>chamber</th>\n",
       "      <th>congress</th>\n",
       "      <th>legis_num</th>\n",
       "      <th>majority</th>\n",
       "      <th>...</th>\n",
       "      <th>vote</th>\n",
       "      <th>vote_desc</th>\n",
       "      <th>vote_question</th>\n",
       "      <th>vote_result</th>\n",
       "      <th>vote_type</th>\n",
       "      <th>sponsor</th>\n",
       "      <th>sponsor_id</th>\n",
       "      <th>sponsor_party</th>\n",
       "      <th>sponsor_state</th>\n",
       "      <th>sponsor_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5103690</th>\n",
       "      <td>5103690</td>\n",
       "      <td>413</td>\n",
       "      <td>2835512</td>\n",
       "      <td>2835512</td>\n",
       "      <td>19-Mar-2015</td>\n",
       "      <td>12:08 PM</td>\n",
       "      <td>U.S. House of Representatives</td>\n",
       "      <td>114</td>\n",
       "      <td>S J RES 8</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>Yea</td>\n",
       "      <td>Providing for congressional disapproval under ...</td>\n",
       "      <td>On Passage</td>\n",
       "      <td>Passed</td>\n",
       "      <td>YEA-AND-NAY</td>\n",
       "      <td>Lamar Alexander</td>\n",
       "      <td>A000360</td>\n",
       "      <td>R</td>\n",
       "      <td>TN</td>\n",
       "      <td>https://api.propublica.org/congress/v1/members...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103691</th>\n",
       "      <td>5103691</td>\n",
       "      <td>414</td>\n",
       "      <td>2835513</td>\n",
       "      <td>2835513</td>\n",
       "      <td>19-Mar-2015</td>\n",
       "      <td>12:08 PM</td>\n",
       "      <td>U.S. House of Representatives</td>\n",
       "      <td>114</td>\n",
       "      <td>S J RES 8</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>Yea</td>\n",
       "      <td>Providing for congressional disapproval under ...</td>\n",
       "      <td>On Passage</td>\n",
       "      <td>Passed</td>\n",
       "      <td>YEA-AND-NAY</td>\n",
       "      <td>Lamar Alexander</td>\n",
       "      <td>A000360</td>\n",
       "      <td>R</td>\n",
       "      <td>TN</td>\n",
       "      <td>https://api.propublica.org/congress/v1/members...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103692</th>\n",
       "      <td>5103692</td>\n",
       "      <td>415</td>\n",
       "      <td>2835514</td>\n",
       "      <td>2835514</td>\n",
       "      <td>19-Mar-2015</td>\n",
       "      <td>12:08 PM</td>\n",
       "      <td>U.S. House of Representatives</td>\n",
       "      <td>114</td>\n",
       "      <td>S J RES 8</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>Yea</td>\n",
       "      <td>Providing for congressional disapproval under ...</td>\n",
       "      <td>On Passage</td>\n",
       "      <td>Passed</td>\n",
       "      <td>YEA-AND-NAY</td>\n",
       "      <td>Lamar Alexander</td>\n",
       "      <td>A000360</td>\n",
       "      <td>R</td>\n",
       "      <td>TN</td>\n",
       "      <td>https://api.propublica.org/congress/v1/members...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103693</th>\n",
       "      <td>5103693</td>\n",
       "      <td>416</td>\n",
       "      <td>2835515</td>\n",
       "      <td>2835515</td>\n",
       "      <td>19-Mar-2015</td>\n",
       "      <td>12:08 PM</td>\n",
       "      <td>U.S. House of Representatives</td>\n",
       "      <td>114</td>\n",
       "      <td>S J RES 8</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>Yea</td>\n",
       "      <td>Providing for congressional disapproval under ...</td>\n",
       "      <td>On Passage</td>\n",
       "      <td>Passed</td>\n",
       "      <td>YEA-AND-NAY</td>\n",
       "      <td>Lamar Alexander</td>\n",
       "      <td>A000360</td>\n",
       "      <td>R</td>\n",
       "      <td>TN</td>\n",
       "      <td>https://api.propublica.org/congress/v1/members...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103694</th>\n",
       "      <td>5103694</td>\n",
       "      <td>417</td>\n",
       "      <td>2835516</td>\n",
       "      <td>2835516</td>\n",
       "      <td>19-Mar-2015</td>\n",
       "      <td>12:08 PM</td>\n",
       "      <td>U.S. House of Representatives</td>\n",
       "      <td>114</td>\n",
       "      <td>S J RES 8</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>Yea</td>\n",
       "      <td>Providing for congressional disapproval under ...</td>\n",
       "      <td>On Passage</td>\n",
       "      <td>Passed</td>\n",
       "      <td>YEA-AND-NAY</td>\n",
       "      <td>Lamar Alexander</td>\n",
       "      <td>A000360</td>\n",
       "      <td>R</td>\n",
       "      <td>TN</td>\n",
       "      <td>https://api.propublica.org/congress/v1/members...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  level_0    index  Unnamed: 0.1  action_date action_time  \\\n",
       "5103690     5103690      413  2835512       2835512  19-Mar-2015    12:08 PM   \n",
       "5103691     5103691      414  2835513       2835513  19-Mar-2015    12:08 PM   \n",
       "5103692     5103692      415  2835514       2835514  19-Mar-2015    12:08 PM   \n",
       "5103693     5103693      416  2835515       2835515  19-Mar-2015    12:08 PM   \n",
       "5103694     5103694      417  2835516       2835516  19-Mar-2015    12:08 PM   \n",
       "\n",
       "                               chamber  congress  legis_num majority  \\\n",
       "5103690  U.S. House of Representatives       114  S J RES 8        R   \n",
       "5103691  U.S. House of Representatives       114  S J RES 8        R   \n",
       "5103692  U.S. House of Representatives       114  S J RES 8        R   \n",
       "5103693  U.S. House of Representatives       114  S J RES 8        R   \n",
       "5103694  U.S. House of Representatives       114  S J RES 8        R   \n",
       "\n",
       "                               ...                         vote  \\\n",
       "5103690                        ...                          Yea   \n",
       "5103691                        ...                          Yea   \n",
       "5103692                        ...                          Yea   \n",
       "5103693                        ...                          Yea   \n",
       "5103694                        ...                          Yea   \n",
       "\n",
       "                                                 vote_desc vote_question  \\\n",
       "5103690  Providing for congressional disapproval under ...    On Passage   \n",
       "5103691  Providing for congressional disapproval under ...    On Passage   \n",
       "5103692  Providing for congressional disapproval under ...    On Passage   \n",
       "5103693  Providing for congressional disapproval under ...    On Passage   \n",
       "5103694  Providing for congressional disapproval under ...    On Passage   \n",
       "\n",
       "         vote_result    vote_type          sponsor sponsor_id sponsor_party  \\\n",
       "5103690       Passed  YEA-AND-NAY  Lamar Alexander    A000360             R   \n",
       "5103691       Passed  YEA-AND-NAY  Lamar Alexander    A000360             R   \n",
       "5103692       Passed  YEA-AND-NAY  Lamar Alexander    A000360             R   \n",
       "5103693       Passed  YEA-AND-NAY  Lamar Alexander    A000360             R   \n",
       "5103694       Passed  YEA-AND-NAY  Lamar Alexander    A000360             R   \n",
       "\n",
       "        sponsor_state                                        sponsor_uri  \n",
       "5103690            TN  https://api.propublica.org/congress/v1/members...  \n",
       "5103691            TN  https://api.propublica.org/congress/v1/members...  \n",
       "5103692            TN  https://api.propublica.org/congress/v1/members...  \n",
       "5103693            TN  https://api.propublica.org/congress/v1/members...  \n",
       "5103694            TN  https://api.propublica.org/congress/v1/members...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.read_csv('../data/df_vote_final.csv')\n",
    "df_final = df_final[df_final['vote'].isin(['Yea', 'Nay'])]\n",
    "print(df_final['vote'].unique())\n",
    "print(df_final.columns)\n",
    "df_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('/home/sonic/.keras/datasets/GoogleNews-vectors-negative300.bin',\n",
    "                                                        binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "replace_puncts = {'`': \"'\", '′': \"'\", '“':'\"', '”': '\"', '‘': \"'\"}\n",
    "\n",
    "strip_chars = [',', '.', '\"', ':', ')', '(', '-', '|', ';', \"'\", '[', ']', '>', '=', '+', '\\\\', '•',  '~', '@', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█',\n",
    " '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦',\n",
    " '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', \n",
    " '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', \n",
    " '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']\n",
    "\n",
    "puncts = ['!', '?', '$', '&', '/', '%', '#', '*','£']\n",
    "\n",
    "def clean_str(x):\n",
    "    x = str(x)\n",
    "    \n",
    "    x = x.lower()\n",
    "    \n",
    "    x = re.sub(r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})\", \"url\", x)\n",
    "    \n",
    "    for k, v in replace_puncts.items():\n",
    "        x = x.replace(k, \" {v} \")\n",
    "        \n",
    "    for punct in strip_chars:\n",
    "        x = x.replace(punct, ' ') \n",
    "    \n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, ' {punct} ')\n",
    "        \n",
    "    x = x.replace(\" '\", \" \")\n",
    "    x = x.replace(\"' \", \" \")\n",
    "        \n",
    "    return x\n",
    "\n",
    "\n",
    "df_bills['billText_clean'] = df_bills['billText'].apply(clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u s  very  has trump {punct} \n"
     ]
    }
   ],
   "source": [
    "print(clean_str('u.s \\'very\" has trump!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text stats\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count      4062.000000\n",
       "mean       3964.086411\n",
       "std       12035.121352\n",
       "min           1.000000\n",
       "25%         256.250000\n",
       "50%         572.000000\n",
       "75%        1821.750000\n",
       "max      120490.000000\n",
       "Name: l, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bills['l'] = df_bills['billText_clean'].apply(lambda x: len(str(x).split(' ')))\n",
    "print('text stats')\n",
    "# df_bills['l'].plot.hist(bins=5, alpha=0.5)\n",
    "df_bills['l'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ( df_bills['billText'].iloc[2])\n",
    "# print ( '*' * 50)\n",
    "# print ( df_bills['billText_clean'].iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weights(name, model):\n",
    "    \"\"\"Extract weights from a neural network model\"\"\"\n",
    "    \n",
    "    # Extract weights\n",
    "    weight_layer = model.get_layer(name)\n",
    "    weights = weight_layer.get_weights()[0]\n",
    "    \n",
    "    # Normalize\n",
    "    weights = weights / np.linalg.norm(weights, axis = 1).reshape((-1, 1))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def stripNonAlphaNum(text):\n",
    "#     return u' '.join(re.compile(r'\\W+', re.UNICODE).split(text))\n",
    "\n",
    "# # don't run\n",
    "# df_bills['billText_clean'] = df_bills['billText'].apply(str)\n",
    "# print(df_bills['billText_clean'].iloc[200])\n",
    "# df_bills['billText_clean'] = df_bills['billText_clean'].apply(stripNonAlphaNum)\n",
    "# print('*' * 100)\n",
    "# print ( df_bills['billText_clean'].iloc[200])\n",
    "# df_bills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# import string\n",
    "# import re\n",
    "# from collections import Counter\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# stopwords = stopwords.words('english')\n",
    "# custome = [\".--\", \"\\'\\'\", \"b\", \"c\"]\n",
    "# stopwords.extend(custome)\n",
    "# print(stopwords)\n",
    "\n",
    "# punctuations = string.punctuation\n",
    "# def cleanup_text(docs, logging=False):\n",
    "#     texts = []\n",
    "#     counter = 1\n",
    "#     for doc in tqdm(docs):\n",
    "#         doc = nlp(doc, disable=['parser', 'ner'])\n",
    "#         tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n",
    "#         tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]\n",
    "# #         tokens = ' '.join(tokens)\n",
    "#         print(tokens)\n",
    "#         texts.append(tokens)\n",
    "#     return pd.Series(texts)\n",
    "\n",
    "# df_bills['billText'] = df_bills['billText'].apply(str)\n",
    "# bill_text = df_bills['billText'][:1].values\n",
    "# print(bill_text[:1])\n",
    "# text_clean = cleanup_text(bill_text)\n",
    "# text_clean = ' '.join(bill_text).split()\n",
    "\n",
    "# text_counts = Counter(text_clean)\n",
    "\n",
    "# text_common_words = [word[0] for word in text_counts.most_common(20)]\n",
    "# print(text_common_words)\n",
    "# text_common_counts = [word[1] for word in text_counts.most_common(20)]\n",
    "\n",
    "# fig = plt.figure(figsize=(18,6))\n",
    "# sns.barplot(x = text_common_words, y = text_common_counts)\n",
    "# plt.title('Most Common Words')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_words = 20000\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "def process_doc(X):\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=max_words,lower=True, split=' ', \n",
    "                          filters='\"#%&()*+-/<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                          char_level=False, oov_token=u'<UNK>')\n",
    "\n",
    "    X_text = X['billText_clean'].values\n",
    "    tokenizer.fit_on_texts(X_text)\n",
    "    print(X.shape)\n",
    "    \n",
    "    X_seq = np.array(tokenizer.texts_to_sequences(X_text))\n",
    "    X_seq = pad_sequences(X_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "    print('X_seq', X_seq.shape)\n",
    "\n",
    "    count_vect = CountVectorizer()\n",
    "    X_train_counts = count_vect.fit_transform(X_text)\n",
    "\n",
    "    tf_transformer = TfidfTransformer().fit(X_train_counts)\n",
    "    X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "\n",
    "    x_emb = {}\n",
    "    #     tokens = nltk.word_tokenize(list(X))\n",
    "#     print('tokens.shape', tokens.shape)\n",
    "\n",
    "    for idx, doc in tqdm(X.iterrows()): #look up each doc in model\n",
    "#         print(doc['legis_num'], doc['billText'])\n",
    "        x_emb[doc['legis_num']] = document_vector(word2vec_model, nltk.word_tokenize(doc['billText_clean'].lower()))\n",
    "\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "\n",
    "    return np.array(X_seq), word_index, x_emb, X_train_tf, X_train_counts\n",
    "\n",
    "def document_vector(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.vocab]\n",
    "    return np.mean(word2vec_model[doc], axis=0)\n",
    "\n",
    "\n",
    "def has_vector_representation(word2vec_model, doc):\n",
    "    \"\"\"check if at least one word of the document is in the\n",
    "    word2vec dictionary\"\"\"\n",
    "    return not all(word not in word2vec_model.vocab for word in doc)\n",
    "\n",
    "\n",
    "df_bills['billText_clean'] = df_bills['billText_clean'].apply(str)\n",
    "X_seq, word_index, X_emb, X_train_tf, X_train_counts = process_doc(df_bills)\n",
    "# df_bills['X_seq'] = X_seq\n",
    "# df_bills['X_emb'] = X_emb\n",
    "# df_bills['X_train_tf'] = X_train_tf\n",
    "# df_bills['X_train_counts'] = X_train_counts\n",
    "\n",
    "# print(X_emb.shape)\n",
    "print(X_emb['H R 5010'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "#     print(history.history)\n",
    "    df = pd.DataFrame(history.history)\n",
    "    print(df.describe())\n",
    "    df.plot(xticks=range(epochs))\n",
    "#     print(history.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot data\n",
    "# fig, ax = plt.subplots(figsize=(15,7))\n",
    "# # print(dataset.groupby(['name'])['legis_num'].count())\n",
    "# print()\n",
    "# dataset.groupby(['name_id'])['legis_num'].count().plot(kind='hist', bins=100, alpha=0.5)\n",
    "# # dataset.groupby(['name']).count()['legis_num'].plot(ax=ax, kind='hist', bins=100, alpha=0.5)\n",
    "# plt.show()\n",
    "# # print(dataset.groupby(['legis_num'])['name_id'].count())\n",
    "# # dataset.groupby(['legis_num'])['name_id'].count().plot(kind='hist', bins=10, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('/home/sonic/.keras/datasets/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_latent_factors = 100\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "vocab_size = len(word_index) + 1\n",
    "print(len(word_index))\n",
    "\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import glorot_uniform  # Or your initializer of choice\n",
    "from tqdm import tqdm\n",
    "\n",
    "def reset_weights(model):\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)\n",
    "\n",
    "def getEmbeddingModel():\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    e = Embedding(300, EMBEDDING_DIM, input_length=300, name='embedding_layer', trainable=True)\n",
    "    model.add(e)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid', name='pred'))\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def getEmbeddingConvModel():\n",
    "    sequence_input = Input(shape=(300,), dtype='int32')\n",
    "    embedding = Embedding(300, EMBEDDING_DIM, input_length=300, name='embedding_layer')\n",
    "    embedded_sequences = embedding(sequence_input)\n",
    "    x = Conv1D(256, 4, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "    x = Conv1D(128, 4, activation='relu')(x)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "    x = Conv1D(64, 4, activation='relu')(x)\n",
    "    x = MaxPooling1D(4)(x)  # global max pooling\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    preds = Dense(1, activation='softmax')(x)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "# print(embedding_matrix.shape)\n",
    "# print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: round(float(majority)/float(count), 2) for cls, count in counter.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from keras.layers import Input, Embedding, Dense, Flatten, Dropout, concatenate\n",
    "from keras.layers import BatchNormalization, SpatialDropout1D\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def getDataset(df):\n",
    "    dataset = df[['name', 'legis_num', 'vote', 'party',\n",
    "                  'sponsor_party', 'sponsor_state', 'sponsor_id']]\n",
    "#     print(df.columns)\n",
    "    dataset['bill_id'] = dataset.legis_num.astype('category').cat.codes.values\n",
    "    dataset['name_id'] = dataset.name.astype('category').cat.codes.values\n",
    "    dataset['vote_orig'] = dataset['vote']\n",
    "    dataset['vote'] = dataset.vote.astype('category').cat.codes.values\n",
    "\n",
    "    dataset['sponsor_party'] = dataset.sponsor_party.astype('category').cat.codes.values\n",
    "    dataset['sponsor_id'] = dataset.sponsor_id.astype('category').cat.codes.values\n",
    "    dataset['sponsor_state'] = dataset.sponsor_state.astype('category').cat.codes.values\n",
    "    # dataset.drop(columns=['name', 'legis_num'], inplace=True)\n",
    "    dataset = dataset.sample(frac=0.5, replace=True)\n",
    "    dataset.reset_index(inplace=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_matrix_factorisation(n_bill, n_users):\n",
    "    legistlator_input = keras.layers.Input(shape=[1], name='legistlator')\n",
    "    legistlator_embedding = keras.layers.Embedding(n_users, n_latent_factors, mask_zero=False,\n",
    "                                                   embeddings_initializer='lecun_uniform',\n",
    "                                                   name='legistlator-Embedding')(legistlator_input)\n",
    "    legistlator_vec = keras.layers.Flatten(name='FlattenLegistlator')(legistlator_embedding)\n",
    "    \n",
    "    bill_input = keras.layers.Input(shape=[1], name='bill')\n",
    "    bill_embedding = keras.layers.Embedding(n_bill, n_latent_factors, mask_zero=False, \n",
    "                                            embeddings_initializer='lecun_uniform',\n",
    "                                            name='bill-Embedding')(bill_input)\n",
    "    bill_vec = keras.layers.Flatten(name='FlattenBill')(bill_embedding)\n",
    "\n",
    "    prod = keras.layers.dot([bill_vec, legistlator_vec], axes=1, name='DotProduct')\n",
    "    model = keras.Model([legistlator_input, bill_input], prod)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    # SVG(model_to_dot(model,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def runEmbeddingModel(train_df, n_users, n_bill):\n",
    "    embedding_learnt_all = {}\n",
    "    accuracy_all = {}\n",
    "    cp_party = {}\n",
    "    \n",
    "    model = getEmbeddingModel()\n",
    "#     model = getEmbeddingConvModel()\n",
    "#     print(model.summary())\n",
    "    reset_weights(model)\n",
    "    \n",
    "    print(\"running embedding mode;\")\n",
    "    for name, group in tqdm(train_df.groupby(['name_id'])):\n",
    "#         print(name, group.iloc[0]['name'])\n",
    "\n",
    "        labels = []\n",
    "        padded_docs = []\n",
    "        for ind, vote in group.iterrows():\n",
    "            padded_docs.append(X_emb[vote['legis_num']])\n",
    "            labels.append(vote['vote'])\n",
    "\n",
    "        padded_docs = np.array(padded_docs)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        reset_weights(model)\n",
    "        # fit the model\n",
    "        history = model.fit(padded_docs, labels, epochs=epochs, verbose=0)\n",
    "        # plot_history(history)\n",
    "\n",
    "        # evaluate the model\n",
    "        loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "        accuracy_all[group.iloc[0]['name']] = {'loss' : loss, 'accuracy' : accuracy}\n",
    "    #     print('Accuracy: %f' % (accuracy*100))\n",
    "\n",
    "#         print('legistlar embedding', model.get_layer(name='embedding_layer').get_weights()[0].shape)\n",
    "        embedding_learnt_all[group.iloc[0]['name_id']] = model.get_layer(name='embedding_layer').get_weights()[0]\n",
    "        cp_party[group.iloc[0]['name']] = group['party'].unique()[0]\n",
    "    \n",
    "    \n",
    "    return embedding_learnt_all, accuracy_all, cp_party\n",
    "\n",
    "def get_padded_labels(df, legistlator_embedding_learnt, bill_embedding_learnt, embedding_learnt_all):\n",
    "    x_emb = [] \n",
    "    x_name = [] \n",
    "    x_bill = [] \n",
    "    x_emb_learnt = []\n",
    "    labels = []\n",
    "    for ind, vote in df.iterrows():\n",
    "        x_emb.append(X_emb[vote['legis_num']])\n",
    "        x_name.append(legistlator_embedding_learnt[vote['name_id']])\n",
    "        x_bill.append(bill_embedding_learnt[vote['bill_id']])\n",
    "#         x_emb_learnt.append(embedding_learnt_all[vote['name_id']])\n",
    "        labels.append(vote['vote'])\n",
    "    return np.array(x_emb), np.array(x_name), np.array(x_bill), np.array(x_emb_learnt), np.array(labels)\n",
    "\n",
    "def runMultiPredictionModel (train_df, test_df, legistlator_embedding_learnt, bill_embedding_learnt, \n",
    "                             baselines, name):\n",
    "\n",
    "    x_emb_train, x_name_train, x_bill_train, y_train = get_padded_labels(train_df, legistlator_embedding_learnt, bill_embedding_learnt)\n",
    "    print('x_emb.shape', x_emb_train.shape)\n",
    "    print('x_name.shape', x_name_train.shape)\n",
    "    print('x_bill.shape', x_bill_train.shape)\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "    \n",
    "    class_weights = get_class_weights(y_train)\n",
    "    print(y_train)\n",
    "    print('Class weights:', class_weights)\n",
    "\n",
    "    \n",
    "    convModel = getEmbeddingConvModel()\n",
    "\n",
    "    # first input model\n",
    "    visible1 = Input(shape=(300, ), name='bill_embedding', dtype='int32')\n",
    "    embedding = Embedding(300, EMBEDDING_DIM, input_length=300, name='embedding_layer', trainable=True)\n",
    "    embedded_sequences = embedding(visible1)\n",
    "    x = Conv1D(128, 4, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "    x = Conv1D(64, 4, activation='relu')(x)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "#     x = Conv1D(32, 4, activation='relu')(x)\n",
    "#     x = MaxPooling1D(4)(x)  # global max pooling\n",
    "    flat1 = Flatten(name='embedding_flatten')(x)\n",
    "    \n",
    "    # second input model\n",
    "    visible2 = Input(shape=[n_latent_factors], name = 'legislator_cf')\n",
    "    hidden_legis_cf = Dense(dense_n, activation='relu', name='legislator_cf_flatten')(visible2)\n",
    "    \n",
    "    # third input model\n",
    "    visible3 = Input(shape=[n_latent_factors], name = 'bill_cf')\n",
    "    hidden_bill_cf = Dense(dense_n, activation='relu', name='bill_cf_flatten')(visible3)\n",
    "    \n",
    "    # merge input models\n",
    "    merge = concatenate([flat1, hidden_legis_cf, hidden_bill_cf])\n",
    "    merge = BatchNormalization()(merge)\n",
    "    # interpretation model\n",
    "    hidden1 = Dense(128, activation='relu')(merge)\n",
    "    hidden2 = Dense(64, activation='relu')(hidden1)\n",
    "    output = Dense(1, activation='sigmoid')(hidden2)\n",
    "    \n",
    "    model = Model(inputs=[visible1, visible2, visible3], outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    # Fit model\n",
    "    history = model.fit([x_emb_train, x_name_train, x_bill_train], y_train,\n",
    "                        callbacks=[EarlyStopping(monitor='loss', patience=2)], \n",
    "                        epochs=epochs, shuffle=True, class_weight=class_weights, verbose=1)\n",
    "    plot_history(history)    \n",
    "    \n",
    "    # fit the model    \n",
    "#     history = convModel.fit(x_emb_train, y_train, epochs=epochs, verbose=1, class_weight=class_weights)\n",
    "#     plot_history(history)\n",
    "\n",
    "    # evaluate the model\n",
    "    print('Evaluating model')\n",
    "    x_emb_test, x_name_test, x_bill_test, y_test = get_padded_labels(test_df, legistlator_embedding_learnt, bill_embedding_learnt)\n",
    "    y_predict = model.predict([x_emb_test, x_name_test, x_bill_test])\n",
    "    baselines.append({'clfName' : 'Multi','congress': name,\n",
    "                      'mse' : mean_squared_error(y_test, y_predict.round()), \n",
    "                      'accuracy' : accuracy_score(y_test, y_predict.round())})\n",
    "    print(metrics.classification_report(y_test, y_predict.round(), labels=[0, 1]))\n",
    "    ##################################################################################################\n",
    "#     print('RUN CONV Simple', '*'*50)\n",
    "#     print(convModel.summary())\n",
    "#     # evaluate the model\n",
    "#     y_predict = convModel.predict(x_emb_test)\n",
    "#     baselines.append({'clfName' : 'Conv', 'congress': name,\n",
    "#                       'mse' : mean_squared_error(y_test, y_predict.round()), \n",
    "#                       'accuracy' : accuracy_score(y_test, y_predict.round())})\n",
    "    \n",
    "    \n",
    "\n",
    "def runBaseLines(train, test, clf,clfName, name):\n",
    "    clf.fit(train[['sponsor_id', 'sponsor_party', 'sponsor_state']], train.vote)\n",
    "    y_predict = clf.predict(test[['sponsor_id', 'sponsor_party', 'sponsor_state']])\n",
    "    model_mse = mean_squared_error(test.vote, y_predict)\n",
    "    print(clf)\n",
    "    print(metrics.classification_report(test.vote, y_predict.round(), labels=[0, 1]))\n",
    "    return {'clfName' : clfName, 'mse' : model_mse, 'accuracy' : accuracy_score(test.vote, y_predict), 'congress': name}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runMultiMetaModel(train_df, test_df, embedding_learnt_all, \n",
    "                      legistlator_embedding_learnt, bill_embedding_learnt, baselines, name):\n",
    "    x_emb_train, x_name_train, x_bill_train, x_emb_learnt, y_train = get_padded_labels(train_df, legistlator_embedding_learnt,\n",
    "                                                                         bill_embedding_learnt, embedding_learnt_all)\n",
    "    x_emb_train = np.expand_dims(x_emb_train, axis=2) \n",
    "    print('x_emb.shape', x_emb_train.shape)\n",
    "    print('x_name.shape', x_name_train.shape)\n",
    "    print('x_bill.shape', x_bill_train.shape)\n",
    "    print('x_emb_learnt.shape', x_emb_learnt.shape)\n",
    "#     class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "    class_weights = get_class_weights(y_train)\n",
    "    print('Class weights:', class_weights)\n",
    "\n",
    "    # first input model\n",
    "    visible1 = Input(shape=(300, 1), name='bill_input')\n",
    "    x = Conv1D(128, 4, activation='relu')(visible1)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "    x = Conv1D(64, 4, activation='relu')(x)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "#     x = Conv1D(32, 4, activation='relu')(x)\n",
    "#     x = MaxPooling1D(4)(x)  # global max pooling\n",
    "    flat1 = Flatten(name='embedding_flatten')(x)\n",
    "    \n",
    "    # second input model\n",
    "    legistlator_input = Input(shape=[1], name='legis_input')\n",
    "    legistlator_embedding = Embedding(n_users, n_latent_factors, mask_zero=False,\n",
    "                                                   embeddings_initializer='lecun_uniform', trainable=True,\n",
    "                                                   name='legislator-Embedding')(legistlator_input)\n",
    "    legistlator_vec = Flatten(name='FlattenLegislator')(legistlator_embedding)\n",
    "\n",
    "    \n",
    "    # third input model\n",
    "    visible3 = Input(shape=[n_latent_factors], name = 'legislator_cf')\n",
    "    hidden_legis_cf = Dense(dense_n, activation='relu', name='legislator_cf_flatten')(visible3)\n",
    "    \n",
    "    # merge input models\n",
    "    merge = concatenate([flat1, legistlator_vec, hidden_legis_cf])\n",
    "    merge = BatchNormalization()(merge)\n",
    "    # interpretation model\n",
    "    hidden1 = Dense(128, activation='relu')(merge)\n",
    "    hidden2 = Dense(64, activation='relu')(hidden1)\n",
    "    output  = Dense(1, activation='sigmoid')(hidden2)\n",
    "    \n",
    "    model = Model(inputs=[visible1, legistlator_input, visible3], outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy', 'mse','mape'])\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file='model.png')\n",
    "    # Fit model\n",
    "    history = model.fit([x_emb_train, train_df.name_id, x_name_train], y_train,\n",
    "                        callbacks=[EarlyStopping(monitor='loss', patience=2)], \n",
    "                        epochs=epochs, shuffle=True, class_weight=class_weights, verbose=1)\n",
    "    plot_history(history)\n",
    "    \n",
    "    # evaluate the model\n",
    "    print('Evaluating model')\n",
    "    x_emb_test, x_name_test, x_bill_test, x_emb_learnt, y_test = get_padded_labels(test_df, legistlator_embedding_learnt, \n",
    "                                                                     bill_embedding_learnt, embedding_learnt_all)\n",
    "    x_emb_test = np.expand_dims(x_emb_test, axis=2)\n",
    "    y_predict = model.predict([x_emb_test, test_df.name_id, x_name_test])\n",
    "    baselines.append({'clfName' : 'Multi','congress': name,\n",
    "                      'mse' : mean_squared_error(y_test, y_predict.round()), \n",
    "                      'accuracy' : accuracy_score(y_test, y_predict.round())})\n",
    "    print(metrics.classification_report(y_test, y_predict.round(), labels=[0, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kraftModel(train_df, test_df):\n",
    "    inputs = Input(shape=(1,))\n",
    "    preds = Dense(1,activation='linear')(inputs)\n",
    "\n",
    "    model = Model(inputs=inputs,outputs=preds)\n",
    "    sgd = keras.optimizers.SGD()\n",
    "    model.compile(optimizer=sgd ,loss='mse')\n",
    "    model.fit(x_,y_, batch_size=1, epochs=10, verbose=1, shuffle=False)\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "\n",
    "# https://github.com/snatch59/keras-autoencoders/blob/master/variational_autoencoder.py\n",
    "def VAE(X_train, train):\n",
    "    batch_size = 100\n",
    "    original_dim = X_train.shape[1]\n",
    "    latent_dim = 2\n",
    "    intermediate_dim = 256\n",
    "    epochs = 50\n",
    "    epsilon_std = 1.0\n",
    "\n",
    "    x = Input(shape=(original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='relu')(x)\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=epsilon_std)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "    # we instantiate these layers separately so as to reuse them later\n",
    "    decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "    decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "    h_decoded = decoder_h(z)\n",
    "    x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "    # instantiate VAE model\n",
    "    vae = Model(x, x_decoded_mean)\n",
    "\n",
    "    # Compute VAE loss\n",
    "    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='rmsprop', metrics=['accuracy', 'mse'])\n",
    "    print(vae.summary())\n",
    "\n",
    "\n",
    "    history = vae.fit(X_train, shuffle=True, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    plot_history(history)\n",
    "\n",
    "    # build a model to project inputs on the latent space\n",
    "    encoder = Model(x, z_mean)\n",
    "\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    from sklearn import preprocessing\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    colors = [ 'b','g', 'r']\n",
    "    y = []\n",
    "    cp_party = {}\n",
    "    \n",
    "    train = train.drop_duplicates(subset='name_id', keep=\"last\")\n",
    "    print('train.shape', train.shape)\n",
    "    for name, group in train.groupby(['name_id']):\n",
    "        cp_party[group.iloc[0]['name_id']] = group['party'].unique()[0]\n",
    "        y.append(group['party'].unique()[0])\n",
    "    \n",
    "    print(len(cp_party))\n",
    "#     for i in range(train.shape[0]):\n",
    "#         y.append(cp_party[i])\n",
    "        \n",
    "    print(y)\n",
    "    le.fit(y)\n",
    "    print('classes', le.classes_)\n",
    "    y = le.transform(y)\n",
    "#     print(y)\n",
    "    x_test_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
    "    print('x_test_encoded.shape', x_test_encoded.shape)\n",
    "    plt.figure(figsize=(8, 6), dpi=100)\n",
    "    plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y)\n",
    "#     for color, i, target_name in zip(colors, [0, 1, 2], le.classes_):\n",
    "#         plt.scatter(x_test_encoded[y == i, 0], x_test_encoded[y == i, 1],\n",
    "#                     cmap=matplotlib.colors.ListedColormap(colors),\n",
    "#                     color=color, alpha=.6, lw=2, label=target_name)\n",
    "    plt.title('Variational Autoencoder')\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "\n",
    "def deep_autoencoder(X_train, train):\n",
    "    print('running autoencoder')\n",
    "    input_dim = X_train.shape[1]\n",
    "    x_input = Input(shape=(input_dim, ))\n",
    "    encoded = Dense(128, activation='relu', kernel_initializer='glorot_uniform')(x_input)\n",
    "    encoded = Dense(64, activation='relu')(encoded)\n",
    "    encoded = Dense(32, activation='relu',  name='encoded')(encoded)\n",
    "\n",
    "    decoded = Dense(64, activation='relu')(encoded)\n",
    "    decoded = Dense(128, activation='relu')(decoded)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "    autoencoder = Model(x_input, decoded)\n",
    "    \n",
    "#     loss = 'mean_squared_error'\n",
    "    loss = 'binary_crossentropy'\n",
    "    autoencoder.compile(optimizer='adam', loss=loss, metrics=['accuracy', 'mse'])\n",
    "    print(autoencoder.summary())\n",
    "    history = autoencoder.fit(X_train, X_train, verbose=0, epochs=epochs)\n",
    "    plot_history(history)\n",
    "    \n",
    "    ###\n",
    "    names = [weight.name for layer in autoencoder.layers for weight in layer.weights]\n",
    "    weights = autoencoder.get_weights()\n",
    "\n",
    "    for name, weight in zip(names, weights):\n",
    "        print(name, weight.shape)\n",
    "    ########################################################################\n",
    "    activations = autoencoder.predict(X_train)\n",
    "    print('activations.shape',activations.shape)\n",
    "    ########################################################################\n",
    "    from sklearn import preprocessing\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    colors = [ 'b','g', 'r']\n",
    "    y = []\n",
    "    cp_party = {}\n",
    "    for name, group in tqdm(train.groupby(['name_id'])):\n",
    "        cp_party[group.iloc[0]['name_id']] = group['party'].unique()[0]\n",
    "    \n",
    "    print(cp_party)\n",
    "    for i in range(X_train.shape[0]):\n",
    "        y.append(cp_party[i])\n",
    "        \n",
    "    print(y)\n",
    "    le.fit(y)\n",
    "    print(le.classes_)\n",
    "    y = le.transform(y)\n",
    "    print(y)\n",
    "    X_tsne = TSNE(n_components=2, verbose=2).fit_transform(activations)\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(activations)\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(10, 10),)\n",
    "#     plt.scatter(X_tsne[:, 0], X_tsne[:, 1], label=y, c=colors, \n",
    "#                 cmap=matplotlib.colors.ListedColormap(colors), alpha=0.6)\n",
    "\n",
    "    for color, i, target_name in zip(colors, [0, 1, 2], le.classes_):\n",
    "        plt.scatter(X_tsne[y == i, 0], X_tsne[y == i, 1], cmap=matplotlib.colors.ListedColormap(colors),\n",
    "                    color=color, alpha=.6, lw=2, label=target_name)\n",
    "    plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "    plt.title('TSNE plot')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 10),)\n",
    "    for color, i, target_name in zip(colors, [0, 1, 2], le.classes_):\n",
    "        plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], cmap=matplotlib.colors.ListedColormap(colors),\n",
    "                    color=color, alpha=.6, lw=2, label=target_name)\n",
    "    plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "    plt.title('PCA plot')\n",
    "    plt.show()\n",
    "    ########################################################################\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/snatch59/keras-autoencoders/blob/master/variational_autoencoder.py\n",
    "def VAE(X_train, train):\n",
    "    batch_size = 100\n",
    "    original_dim = X_train.shape[1]\n",
    "    latent_dim = 2\n",
    "    intermediate_dim = 256\n",
    "    epochs = 30\n",
    "    epsilon_std = 1.0\n",
    "\n",
    "    x = Input(shape=(original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='relu')(x)\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=epsilon_std)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "    # we instantiate these layers separately so as to reuse them later\n",
    "    decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "    decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "    h_decoded = decoder_h(z)\n",
    "    x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "    # instantiate VAE model\n",
    "    vae = Model(x, x_decoded_mean)\n",
    "\n",
    "    # Compute VAE loss\n",
    "    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='rmsprop', metrics=['accuracy', 'mse'])\n",
    "    print(vae.summary())\n",
    "\n",
    "\n",
    "    history = vae.fit(X_train, shuffle=True, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    plot_history(history)\n",
    "\n",
    "    # build a model to project inputs on the latent space\n",
    "    encoder = Model(x, z_mean)\n",
    "\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    from sklearn import preprocessing\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    colors = ['b','g', 'r']\n",
    "    y = []\n",
    "    cp_party = {}\n",
    "    \n",
    "    train = train.drop_duplicates(subset='name_id', keep=\"last\")\n",
    "    print('train.shape', train.shape)\n",
    "    y.append('R')\n",
    "    for name, group in train.groupby(['name_id']):\n",
    "        cp_party[group.iloc[0]['name_id']] = group['party'].unique()[0]\n",
    "        y.append(group['party'].unique()[0])\n",
    "    \n",
    "    print(len(cp_party))\n",
    "#     for i in range(train.shape[0]):\n",
    "#         y.append(cp_party[i])\n",
    "        \n",
    "    print(y)\n",
    "    le.fit(y)\n",
    "    print('classes', le.classes_)\n",
    "    y = le.transform(y)\n",
    "#     print(y)\n",
    "    x_test_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
    "    print('x_test_encoded.shape', x_test_encoded.shape)\n",
    "    plt.figure(figsize=(8, 6), dpi=100)\n",
    "    plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y)\n",
    "#     for color, i, target_name in zip(colors, [0, 1, 2], le.classes_):\n",
    "#         plt.scatter(x_test_encoded[y == i, 0], x_test_encoded[y == i, 1],\n",
    "#                     cmap=matplotlib.colors.ListedColormap(colors),\n",
    "#                     color=color, alpha=.6, lw=2, label=target_name)\n",
    "    plt.title('Variational Autoencoder')\n",
    "    plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = getDataset(df_final)\n",
    "print(dataset.shape)\n",
    "n_users, n_bill = len(dataset.name_id.unique()) + 1, len(dataset.bill_id.unique()) + 1\n",
    "print('number of legsitlators:', n_users)\n",
    "print('number of bills', n_bill)\n",
    "#     print(dataset.name_id.unique())\n",
    "\n",
    "# RUN MATRIX AUTOENCODER #######################################################################\n",
    "vote_matrix = getVoteMatrix(dataset, n_users, n_bill)\n",
    "print('running vae')\n",
    "#     deep_autoencoder(vote_matrix, train)\n",
    "VAE(vote_matrix, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_autoencoder(vote_matrix, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "\n",
    "grouped_congress = df_final.groupby('congress')\n",
    "embedding_learnt_congress_all = {}\n",
    "bill_embedding_learnt_all = {}\n",
    "legistlator_embedding_learnt_all = {}\n",
    "congress_info = {}\n",
    "cp_party_all = {}\n",
    "baselines = []\n",
    "\n",
    "dense_n = 100\n",
    "droprate=0.25\n",
    "\n",
    "#EPOCHS\n",
    "epochs = 30\n",
    "\n",
    "\n",
    "for name, group in grouped_congress:\n",
    "    print('Processing congress', name)\n",
    "    print('congress shape', group.shape)\n",
    "    \n",
    "    df_votes_filtered = df_final[df_final['congress'] == name]\n",
    "    num_legistlators = len(df_votes_filtered['name'].unique())\n",
    "    num_bills = len(df_votes_filtered['legis_num'].unique())\n",
    "    print('number of legistlators', num_legistlators)\n",
    "\n",
    "    dataset = getDataset(df_votes_filtered)\n",
    "    train, test = train_test_split(dataset, test_size=0.2)\n",
    "    print('train.shape', train.shape)\n",
    "    print('test.shape', test.shape)\n",
    "    congress_info[name] = {'num_legislators': num_legistlators, 'num_bills' : num_bills, \n",
    "                           'dataset.shape' : dataset.shape[0], 'train.shape': train.shape[0], 'test.shape': test.shape[0]}\n",
    "    \n",
    "    # Run base model ###############################################################################\n",
    "#     for clfName, clf in ({'Majority' :  DummyClassifier(strategy=\"most_frequent\"), \n",
    "#                   'Decision Tree' : DecisionTreeClassifier(), \n",
    "#                   'RandomForest' : RandomForestClassifier()}.items()):\n",
    "#         baselines.append(runBaseLines(train, test, clf, clfName, name))\n",
    "    ################################################################################################\n",
    "    \n",
    "    n_users, n_bill = len(dataset.name_id.unique()), len(dataset.bill_id.unique())\n",
    "    print('number of legsitlators:', n_users)\n",
    "    print('number of bills', n_bill)\n",
    "#     print(dataset.name_id.unique())\n",
    "    \n",
    "    # RUN MATRIX AUTOENCODER #######################################################################\n",
    "    vote_matrix = getVoteMatrix(train, n_users, n_bill)\n",
    "    \n",
    "#     deep_autoencoder(vote_matrix, train)\n",
    "    VAE(vote_matrix, train)\n",
    "    ################################################################################################\n",
    "  \n",
    "    # Run embedding model ##########################################################################\n",
    "#     %time embedding_learnt_all, accuracy_all, cp_party = runEmbeddingModel(train, n_users, n_bill)\n",
    "#     df_performace = pd.DataFrame(accuracy_all)\n",
    "#     embedding_learnt_congress_all[name] = embedding_learnt_all\n",
    "#     cp_party_all[name] = cp_party\n",
    "#     print('average accuracy', df_performace.loc['accuracy'].mean())\n",
    "#     print('average loss', df_performace.loc['loss'].mean())\n",
    "    ################################################################################################\n",
    "\n",
    "    # Run Matrix factorization model ###############################################################\n",
    "#     print('Runing Matrix Factorisation')\n",
    "#     MF_model = get_matrix_factorisation(n_bill, n_users)\n",
    "# #     print(MF_model.summary())\n",
    "#     %time history = MF_model.fit([train.name_id, train.bill_id], train.vote, epochs=5, verbose=0)\n",
    "#     plot_history(history)\n",
    "#     bill_embedding_learnt = MF_model.get_layer(name='bill-Embedding').get_weights()[0]\n",
    "#     bill_embedding_learnt_all[name] = bill_embedding_learnt\n",
    "#     legistlator_embedding_learnt = MF_model.get_layer(name='legistlator-Embedding').get_weights()[0]\n",
    "#     legistlator_embedding_learnt_all[name] = legistlator_embedding_learnt \n",
    "#     print('bill_embedding_learnt.shape', bill_embedding_learnt.shape)\n",
    "#     print('legistlator_embedding_learnt.shape', legistlator_embedding_learnt.shape)\n",
    "    #################################################################################################\n",
    "    \n",
    "    ########PREDICTION ##############################################################################\n",
    "#     runMultiPredictionModel(train, test, legistlator_embedding_learnt, bill_embedding_learnt, baselines, name)\n",
    "#     runMultiMetaModel(train, test, embedding_learnt_all, legistlator_embedding_learnt, bill_embedding_learnt, baselines, name)\n",
    "    #################################################################################################\n",
    "#     print(baselines)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AYE = 1\n",
    "NAY = -1\n",
    "\n",
    "def getVoteMatrix(df, n_users, n_bill):\n",
    "    mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "    # Draw random samples from a normal (Gaussian) distribution.\n",
    "    vote_matrix = np.random.normal(mu, sigma, (n_users, n_bill))\n",
    "\n",
    "    for _, vote in df.iterrows():\n",
    "        if vote['vote_orig'] == 'Yea':\n",
    "            vote_matrix[vote['name_id'], vote['bill_id']] = AYE\n",
    "        elif vote['vote_orig'] == 'Nay':\n",
    "            vote_matrix[vote['name_id'], vote['bill_id']] = NAY\n",
    "            \n",
    "#     print(vote_matrix)\n",
    "#     vote_matrix_df = pd.DataFrame(vote_matrix)\n",
    "#     print(vote_matrix_df.T.describe())\n",
    "#     vote_matrix = np.expand_dims(vote_matrix, axis=0)\n",
    "    print('vote_matrix.shape', vote_matrix.shape)\n",
    "    return vote_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(baselines)\n",
    "baseLine_df = pd.DataFrame(baselines)\n",
    "# print(baseLine_df.T.to_latex())\n",
    "# print(baseLine_df.groupby(['congress', 'clfName'], as_index=False).apply(list))\n",
    "print(baseLine_df.to_latex())\n",
    "baseLine_df.to_csv('baselines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(congress_info)\n",
    "print(df_info.to_latex())\n",
    "df_info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress = 106\n",
    "legistlator_embedding_learnt = legistlator_embedding_learnt_all[congress]\n",
    "congress_embedding = embedding_learnt_congress_all[congress]\n",
    "print(len(congress_embedding.keys()))\n",
    "print(legistlator_embedding_learnt.shape)\n",
    "print(congress_embedding[0].shape)\n",
    "print(congress_embedding[0])\n",
    "legistlator_embedding_learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "tqdm.pandas(desc='progress-bar')\n",
    "\n",
    "congress = 106\n",
    "# print(embedding_learnt_congress_all[congress])\n",
    "congress_embedding = embedding_learnt_congress_all[congress]\n",
    "congress_cp = cp_party_all[congress]\n",
    "# print(congress_cp)\n",
    "print(type(congress_embedding))\n",
    "dictList = []\n",
    "y = []\n",
    " \n",
    "import itertools\n",
    "\n",
    "for key, value in congress_embedding.items():\n",
    "    temp = value.reshape(-1)\n",
    "    y.append(congress_cp[key])\n",
    "#     print(key, list(itertools.chain(*value)))\n",
    "    dictList.append(temp)\n",
    "    \n",
    "print(np.array(dictList,object).shape)\n",
    "print(np.array(dictList,object)[0].shape)\n",
    "# print(np.array(dictList,object)[0])\n",
    "# print(congress_embedding.items().values().shape)\n",
    "# x = pd.DataFrame(np.array(congress_embedding))\n",
    "x = np.array(dictList,object)\n",
    "print('x', x.shape)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(y)\n",
    "# print(le.classes_)\n",
    "# y = le.transform(y)\n",
    "# print(y)\n",
    "\n",
    "colors = ['b', 'r']\n",
    "\n",
    "X_tsne = TSNE(n_components=2, verbose=2).fit_transform(x)\n",
    "\n",
    "plt.figure(1, figsize=(20, 20),)\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], label=y, s=100,  cmap=matplotlib.colors.ListedColormap(colors), alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_ids = range(2)\n",
    "\n",
    "# choose a color palette with seaborn.\n",
    "num_classes = 2\n",
    "print(np.array(y).flatten().shape)\n",
    "print(y)\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "print(le.classes_)\n",
    "y = le.transform(y)\n",
    "print(y)\n",
    "palette = np.array(sns.color_palette(\"hls\", num_classes))\n",
    "plt.figure(1, figsize=(20, 20),)\n",
    "plt.scatter(X_tsne[:,0], X_tsne[:,1], c=y, lw=0, s=40, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET DATASET STATS\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(12,6))\n",
    "i = 0\n",
    "c = 0\n",
    "for name, group in grouped_congress:\n",
    "    print('Processing congress', name)\n",
    "    print('congress shape', group.shape)\n",
    "    group['vote'].value_counts().plot(ax=axes[c,i], kind='bar', alpha=.5, title=name)\n",
    "    i += 1\n",
    "    if (i == 5):\n",
    "        i = 0\n",
    "        c += 1\n",
    "    \n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.show()\n",
    "    \n",
    "def getStats(name, group):\n",
    "    print('stat information about congress ', name)\n",
    "    print((group['vote'].value_counts()))\n",
    "    group['vote'].value_counts().plot(kind='bar', alpha=.5)\n",
    "    plt.savefig('../figures/%s-vote.png' % name)\n",
    "    print(group['vote_result'].value_counts())\n",
    "    group['vote_result'].value_counts().plot(kind='bar', alpha=.5)\n",
    "    plt.savefig('../figures/%s-vote-result.png' % name)\n",
    "\n",
    "\n",
    "print(df_final['congress'].value_counts().sort_index())\n",
    "df_final['congress'].value_counts().sort_index().plot(kind='bar', alpha=.5)\n",
    "plt.savefig('../figures/dataset-congress.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "# train the VAE on MNIST digits\n",
    "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
