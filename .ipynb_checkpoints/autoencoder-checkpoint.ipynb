{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Add, Multiply\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 435)\n",
      "(167,)\n",
      "(167, 17563)\n",
      "(167, 17563)\n",
      "(167, 300)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vote_matrix_all = np.load('data/vote_matrix_all.npy' )\n",
    "X_seq_all = np.load('data/X_seq_all.npy')\n",
    "word_index_all = np.load('data/X_word_index_all.npy')\n",
    "X_train_tf_all = np.load('data/X_train_tf_all.npy')\n",
    "X_train_counts_all = np.load('data/X_train_counts_all.npy')\n",
    "X_emb_all = np.load('data/X_emb_all.npy')\n",
    "legistlator_all = np.load('data/legistlator_all.npy')\n",
    "\n",
    "print(vote_matrix_all.item()[106].shape)\n",
    "print(X_seq_all.item()[106].shape)\n",
    "# print(word_index_all[106].shape)\n",
    "print(X_train_tf_all.item()[106].shape)\n",
    "print(X_train_counts_all.item()[106].shape)\n",
    "print(X_emb_all.item()[106].shape)\n",
    "# print(legistlator_all.item()[106])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variational\n",
    "\n",
    "def nll(y_true, y_pred):\n",
    "    \"\"\" Negative log likelihood (Bernoulli). \"\"\"\n",
    "\n",
    "    # keras.losses.binary_crossentropy gives the mean\n",
    "    # over the last axis. we require the sum\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "\n",
    "class KLDivergenceLayer(Layer):\n",
    "\n",
    "    \"\"\" Identity transform layer that adds KL divergence\n",
    "    to the final model loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        mu, log_var = inputs\n",
    "\n",
    "        kl_batch = - .5 * K.sum(1 + log_var -\n",
    "                                K.square(mu) -\n",
    "                                K.exp(log_var), axis=-1)\n",
    "\n",
    "        self.add_loss(K.mean(kl_batch), inputs=inputs)\n",
    "\n",
    "        return inputs\n",
    "\n",
    "\n",
    "def get_VAE(original_dim):\n",
    "    decoder = Sequential([\n",
    "        Dense(intermediate_dim, input_dim=latent_dim, activation='relu'),\n",
    "        Dense(original_dim, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    x = Input(shape=(original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='relu')(x)\n",
    "\n",
    "    z_mu = Dense(latent_dim)(h)\n",
    "    z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "    z_mu, z_log_var = KLDivergenceLayer()([z_mu, z_log_var])\n",
    "    z_sigma = Lambda(lambda t: K.exp(.5*t))(z_log_var)\n",
    "\n",
    "    eps = Input(tensor=K.random_normal(stddev=epsilon_std,\n",
    "                                       shape=(K.shape(x)[0], latent_dim)))\n",
    "    z_eps = Multiply()([z_sigma, eps])\n",
    "    z = Add()([z_mu, z_eps])\n",
    "\n",
    "    x_pred = decoder(z)\n",
    "\n",
    "    vae = Model(inputs=[x, eps], outputs=x_pred)\n",
    "    \n",
    "    loss = nll\n",
    "    loss = 'mean_squared_error'\n",
    "    vae.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "    encoder = Model(x, z_mu)\n",
    "    return vae, encoder, decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import glorot_uniform  # Or your initializer of choice\n",
    "\n",
    "def reinitialize(model):\n",
    "    initial_weights = model.get_weights()\n",
    "    new_weights = [glorot_uniform()(w.shape).eval() for w in initial_weights]\n",
    "    model.set_weights(new_weights)\n",
    "    return model\n",
    "      \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_emb (167, 300)\n",
      "vote_matrix (167, 435)\n",
      "X_meta (435, 167, 300)\n",
      "X_train (435, 167, 300)\n",
      "X_train new shape (435, 50100)\n",
      "X_meta new shape (435, 50100)\n",
      "[ 0.44764679 -0.82328323  0.30339417 ...  0.17085549 -1.\n",
      " -0.37614302]\n",
      "[ 0.43058159 -0.76341885  0.28763101 ...  0.0995803  -0.0413523\n",
      "  0.05516363]\n"
     ]
    }
   ],
   "source": [
    "X_emb = X_emb_all.item()[106]\n",
    "vote_matrix = vote_matrix_all.item()[106]\n",
    "print('X_emb', X_emb.shape)\n",
    "print('vote_matrix', vote_matrix.shape)\n",
    "\n",
    "# numpyMatrix = df.as_matrix().astype(float)\n",
    "# scaled_data = preprocessing.scale(numpyMatrix)\n",
    "\n",
    "from sklearn.preprocessing import scale, MinMaxScaler, StandardScaler\n",
    "# X_emb = StandardScaler().fit_transform(X_emb.astype(float))\n",
    "X_emb = scale(X_emb.astype(float))\n",
    "\n",
    "X = []\n",
    "X_meta = []\n",
    "y = []\n",
    "i = 0\n",
    "\n",
    "#     mean = 0.0   # some constant\n",
    "#     std = 1.0    # some constant (standard deviation)\n",
    "#     meta = meta + np.random.normal(mean, std, meta.shape)\n",
    "mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "noise_factor = 0.5\n",
    "\n",
    "X_train = []\n",
    "######\n",
    "# Create Meta for each legistlator\n",
    "for idx, legistlator in enumerate(vote_matrix.T):\n",
    "#     print('np.vstack(legistlator)', np.vstack(legistlator).shape)\n",
    "#     print('legistlator.shape', legistlator.shape)\n",
    "#     legistlator = legistlator + np.random.normal(mu, sigma, legistlator.shape)\n",
    "\n",
    "    meta = np.multiply(X_emb, np.vstack(legistlator)) # Eelementwise multiplication, introducing noise\n",
    "\n",
    "\n",
    "    meta = meta + noise_factor * np.random.normal(mu, sigma, meta.shape)\n",
    "\n",
    "#     print('meta.shape', meta.shape)\n",
    "    \n",
    "    X_meta.append(meta)\n",
    "    X_train.append(X_emb)\n",
    "\n",
    "#     break\n",
    "######\n",
    "X_meta = np.array(X_meta)\n",
    "X_train = np.array(X_train)\n",
    "print('X_meta', X_meta.shape)\n",
    "print('X_train', X_train.shape)\n",
    "\n",
    "\n",
    "# Reshape to flatten the dimentions\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_meta = X_meta.reshape(X_meta.shape[0], -1)\n",
    "# X_train = X_train.reshape(-1, X_train.shape[1], X_train.shape[2], 1)\n",
    "# X_meta = X_meta.reshape(-1, X_meta.shape[1], X_meta.shape[2], 1)\n",
    "\n",
    "X_train =  np.clip(X_train, -1., 1.)\n",
    "X_meta = np.clip(X_meta, -1., 1.)\n",
    "print('X_train new shape', X_train.shape)\n",
    "print('X_meta new shape', X_meta.shape)\n",
    "\n",
    "print(X_train[0])\n",
    "print(X_meta[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_autoencoder(X_train):\n",
    "    input_img = Input(shape=(X_train.shape[1],  ))\n",
    "    encoded = Dense(512, activation='relu', kernel_initializer='glorot_uniform')(input_img)\n",
    "    encoded = Dense(256, activation='relu')(encoded)\n",
    "    encoded = Dense(128, activation='relu',  name='encoded')(encoded)\n",
    "\n",
    "    decoded = Dense(256, activation='relu')(encoded)\n",
    "    decoded = Dense(512, activation='relu')(decoded)\n",
    "    decoded = Dense(X_train.shape[1], activation='sigmoid')(decoded)\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    loss = 'mean_squared_error'\n",
    "#     loss='binary_crossentropy'\n",
    "    autoencoder.compile(optimizer='adam', loss=loss)\n",
    "    return autoencoder\n",
    "\n",
    "def denoiser_autoencoder(X_train):\n",
    "#     input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "    input_img = Input(shape = (X_train.shape[1], X_train.shape[2], 1 ))\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='glorot_uniform')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    # at this point the representation is (7, 7, 32)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return autoencoder\n",
    "\n",
    "    \n",
    "from keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D\n",
    "\n",
    "\n",
    "def conv_autoencoder(X_train):\n",
    "    \n",
    "    input_img = Input(shape = (X_train.shape[1], X_train.shape[2], 1 ))\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', name='encoded')(pool2) #7 x 7 x 128 (small and thick)\n",
    "\n",
    "    #decoder\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 128\n",
    "    up1 = UpSampling2D((2,2))(conv4) # 14 x 14 x 128\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 64\n",
    "    up2 = UpSampling2D((2,2))(conv5) # 28 x 28 x 64\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='decoded')(up2) # 28 x 28 x 1\n",
    "    \n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(loss='mean_squared_error', optimizer = 'RMSprop')\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 50100)             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               25651712  \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "encoded (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 50100)             25701300  \n",
      "=================================================================\n",
      "Total params: 51,681,844\n",
      "Trainable params: 51,681,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "ShuffleSplit(n_splits=3, random_state=0, test_size=0.25, train_size=None)\n",
      "(326, 50100) (109, 50100)\n",
      "(326, 50100) (109, 50100)\n",
      "Epoch 1/10\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.6845\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 2s 5ms/step - loss: 0.3765\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 2s 5ms/step - loss: 0.3293\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 2s 5ms/step - loss: 0.3365\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 2s 5ms/step - loss: 0.3386\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 2s 5ms/step - loss: 0.3390\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 2s 5ms/step - loss: 0.3394\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 2s 5ms/step - loss: 0.3395\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 2s 5ms/step - loss: 0.3396\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 2s 5ms/step - loss: 0.3397\n",
      "{'loss': [0.6845482459828898, 0.37651949115326067, 0.3292677737086829, 0.33646957347729456, 0.3385870910129664, 0.33902595672139363, 0.3393967720262843, 0.3395013898793905, 0.339602349725969, 0.33966123143588106]}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'zip' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a2dda0e9b4a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#         print(name, weight.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'zip' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################\n",
    "# original_dim = \n",
    "intermediate_dim = 256\n",
    "latent_dim = 128\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "epsilon_std = 1.0\n",
    "###################\n",
    "\n",
    "# autoencoder, encoder, decoder = get_VAE(original_dim)\n",
    "autoencoder = deep_autoencoder(X_train)\n",
    "# autoencoder = denoiser_autoencoder(X_train)\n",
    "# autoencoder = conv_autoencoder(X_train)\n",
    "print(autoencoder.summary())\n",
    "\n",
    "rs = ShuffleSplit(n_splits=3, test_size=.25, random_state=0)\n",
    "rs.get_n_splits(X_train)\n",
    "\n",
    "print(rs)\n",
    "\n",
    "def plot_history(history):\n",
    "    print(history.history)\n",
    "    df = pd.DataFrame(history.history)\n",
    "#     print(df.tail())\n",
    "    df.plot(xticks=range(epochs))\n",
    "#     print(history.history.keys())\n",
    "\n",
    "    \n",
    "for train_index, test_index in rs.split(X_train):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_emb_train, X_emb_test = X_train[train_index], X_train[test_index]\n",
    "    X_meta_train, X_meta_test = X_meta[train_index], X_meta[test_index]\n",
    "    \n",
    "    print(X_emb_train.shape, X_emb_test.shape)\n",
    "    print(X_meta_train.shape, X_meta_test.shape)\n",
    "#     break\n",
    "    \n",
    "    history = autoencoder.fit(X_emb_train,\n",
    "        X_meta_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    plot_history(history)\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    names = [weight.name for layer in autoencoder.layers for weight in layer.weights]\n",
    "    weights = autoencoder.get_weights()\n",
    "\n",
    "#     for name, weight in zip(names, weights):\n",
    "#         print(name, weight.shape)\n",
    "        \n",
    "    encoded_weight = \n",
    "    print(model_weights['encoded'].shape, model_weights['encoded'])\n",
    "\n",
    "    ###\n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into a training and testing set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
